{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "69d3b5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import mediapipe as mp\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_faces = mp.solutions.face_detection\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "def mediapipe_detection(image, hand_model, face_model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False                \n",
    "    hand_results = hand_model.process(image)\n",
    "    face_results = face_model.process(image)\n",
    "    image.flags.writeable = True                \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    return image, hand_results, face_results\n",
    "\n",
    "def extract_keypoints_v1(results):\n",
    "    lh = np.zeros((21, 3))\n",
    "    rh = np.zeros((21, 3))\n",
    "    visible = False\n",
    "    if results.multi_hand_landmarks:\n",
    "        visible = True\n",
    "        for index, hand_landmarks in enumerate(results.multi_hand_landmarks):\n",
    "            if results.multi_handedness[index].classification[0].index == 0:\n",
    "                lh = [[res.x, res.y, res.z] for res in\n",
    "                    hand_landmarks.landmark]\n",
    "            else:\n",
    "                rh = [[res.x, res.y, res.z] for res in\n",
    "                            hand_landmarks.landmark]\n",
    "    return np.concatenate([lh, rh], axis=0), visible\n",
    "\n",
    "def extract_keypoints_v2(results):\n",
    "    lh = np.zeros((21, 3))\n",
    "    rh = np.zeros((21, 3))\n",
    "    found = False\n",
    "    if results.multi_hand_landmarks:\n",
    "        found = True\n",
    "\n",
    "        for index, hand_landmarks in enumerate(results.multi_hand_landmarks):\n",
    "            ref = hand_landmarks.landmark[0]\n",
    "            ref = np.array([ref.x, ref.y, ref.z])\n",
    "            min_pos = ref\n",
    "            max_pos = ref\n",
    "            all_pos = []\n",
    "            for res in hand_landmarks.landmark:\n",
    "                norm_pos = np.array([res.x - ref[0], res.y - ref[1], res.z - ref[2]])\n",
    "                all_pos.append(norm_pos)\n",
    "                min_pos = np.minimum(min_pos, np.array([res.x, res.y, res.z]))\n",
    "                max_pos = np.maximum(max_pos, np.array([res.x, res.y, res.z]))\n",
    "            size = max_pos - min_pos\n",
    "            if results.multi_handedness[index].classification[0].index == 0:\n",
    "                lh = [pos / size for pos in\n",
    "                            all_pos]\n",
    "            else:\n",
    "                rh = [pos / size for pos in\n",
    "                            all_pos]\n",
    "    return np.concatenate([lh, rh], axis=0), found\n",
    "\n",
    "def extract_keypoints_v3(hand_results, face_results, w, h):\n",
    "    lh = np.zeros((21, 3))\n",
    "    rh = np.zeros((21, 3))\n",
    "    face_hand_dif = [1000, 1000, 1000]\n",
    "    face_size = np.ones(2)\n",
    "    found = False\n",
    "    if hand_results.multi_hand_landmarks:\n",
    "        found = True\n",
    "\n",
    "        for index, hand_landmarks in enumerate(hand_results.multi_hand_landmarks):\n",
    "            ref = hand_landmarks.landmark[0]\n",
    "            ref = np.array([ref.x, ref.y, ref.z])\n",
    "            min_pos = ref\n",
    "            max_pos = ref\n",
    "            all_pos = []\n",
    "            hand_center = [0, 0]\n",
    "            for res in hand_landmarks.landmark:\n",
    "                hand_center = [curr + new for curr, new in zip(hand_center, [res.x, res.y])]\n",
    "                norm_pos = np.array([res.x - ref[0], res.y - ref[1], res.z])\n",
    "                all_pos.append(norm_pos)\n",
    "                min_pos = np.minimum(min_pos, np.array([res.x, res.y, res.z]))\n",
    "                max_pos = np.maximum(max_pos, np.array([res.x, res.y, res.z]))\n",
    "            hand_center = [pos / len(hand_landmarks.landmark) for pos in hand_center]\n",
    "            max_face_pos = [0, 0]\n",
    "            min_face_pos = [1, 1]\n",
    "            if face_results.detections:\n",
    "                for detection in face_results.detections:\n",
    "                    face_center = [0, 0]\n",
    "                    for keypoint in detection.location_data.relative_keypoints:\n",
    "                        face_center = [pos + point for pos, point in zip(face_center, [keypoint.x, keypoint.y])]\n",
    "                        min_face_pos = np.minimum(min_face_pos, np.array([keypoint.x, keypoint.y]))\n",
    "                        max_face_pos = np.maximum(max_face_pos, np.array([keypoint.x, keypoint.y]))\n",
    "                    face_center = [pos / len(detection.location_data.relative_keypoints) for pos in face_center]\n",
    "                    dif = [face - hand for face, hand in zip(face_center, hand_center)]\n",
    "                    dif.append(1000)\n",
    "                    if sum([abs(val) for val in dif]) < sum([abs(val) for val in face_hand_dif]):\n",
    "                        face_hand_dif = dif\n",
    "            face_size = np.array(max_face_pos) - np.array(min_face_pos)\n",
    "            size = max_pos - min_pos\n",
    "            hand_size = (abs((all_pos[1][0] - all_pos[2][0]) * w) + abs((all_pos[1][1] - all_pos[2][1]) * h) + abs((all_pos[1][2] - all_pos[2][2]) * 2000)) / 10\n",
    "            approx_z = face_size[0] * face_size[1] * 100 - hand_size\n",
    "            face_hand_dif[2] = approx_z\n",
    "            if hand_results.multi_handedness[index].classification[0].index == 0:\n",
    "                lh = [pos / size for pos in\n",
    "                            all_pos]\n",
    "            else:\n",
    "                rh = [pos / size for pos in\n",
    "                            all_pos]\n",
    "    face_hand_dif = np.array(face_hand_dif)\n",
    "    face_size = np.append(face_size, [1])\n",
    "    face_hand_dif = face_hand_dif / face_size\n",
    "    face_hand_dif = face_hand_dif.reshape(1, face_hand_dif.shape[0])\n",
    "    return np.concatenate([lh, rh, face_hand_dif], axis=0), found\n",
    "\n",
    "KEYPOINT_PATH = \"Keypoint Dataset\"\n",
    "DATA_PATH = \"terbisa.v3i.multiclass\"\n",
    "\n",
    "try: \n",
    "    os.makedirs(KEYPOINT_PATH)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "68366b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current folder: test\n",
      "Current class: Anda\n",
      "Current class: Apa\n",
      "Current class: Berhenti\n",
      "Current class: Bodoh\n",
      "Current class: Cantik\n",
      "Current class: Halo\n",
      "Current class: Hati-hati\n",
      "Current class: Lelah\n",
      "Current class: Maaf\n",
      "Current class: Makan\n",
      "Current class: Mau-Ingin\n",
      "Current class: Membaca\n",
      "Current class: Nama\n",
      "Current class: Sama-sama\n",
      "Current class: Saya\n",
      "Current class: Siapa\n",
      "Current class: Sombong\n",
      "Current class: Takut\n",
      "Current class: Terima\n",
      "Current folder: train\n",
      "Current class: Anda\n",
      "Current class: Apa\n",
      "Current class: Berhenti\n",
      "Current class: Bodoh\n",
      "Current class: Cantik\n",
      "Current class: Halo\n",
      "Current class: Hati-hati\n",
      "Current class: Lelah\n",
      "Current class: Maaf\n",
      "Current class: Makan\n",
      "Current class: Mau-Ingin\n",
      "Current class: Membaca\n",
      "Current class: Nama\n",
      "Current class: Sama-sama\n",
      "Current class: Saya\n",
      "Current class: Siapa\n",
      "Current class: Sombong\n",
      "Current class: Takut\n",
      "Current class: Terima\n",
      "Current folder: valid\n",
      "Current class: Anda\n",
      "Current class: Apa\n",
      "Current class: Berhenti\n",
      "Current class: Bodoh\n",
      "Current class: Cantik\n",
      "Current class: Halo\n",
      "Current class: Hati-hati\n",
      "Current class: Lelah\n",
      "Current class: Maaf\n",
      "Current class: Makan\n",
      "Current class: Mau-Ingin\n",
      "Current class: Membaca\n",
      "Current class: Nama\n",
      "Current class: Sama-sama\n",
      "Current class: Saya\n",
      "Current class: Siapa\n",
      "Current class: Sombong\n",
      "Current class: Takut\n",
      "Current class: Terima\n"
     ]
    }
   ],
   "source": [
    "with mp_hands.Hands(static_image_mode=True, min_detection_confidence=0.1) as hands, mp_faces.FaceDetection(min_detection_confidence=0.5) as faces:\n",
    "    for folder in os.listdir(DATA_PATH):\n",
    "        print(\"Current folder: \" + folder)\n",
    "        df = pd.read_csv(os.path.join(DATA_PATH, folder) + \"/_classes.csv\")\n",
    "        for className in df.columns[1:]:\n",
    "            name = className.split()[0]\n",
    "            print(\"Current class: \" + name)\n",
    "            try: \n",
    "                os.makedirs(os.path.join(KEYPOINT_PATH, \"V1\", name))\n",
    "                os.makedirs(os.path.join(KEYPOINT_PATH, \"V2\", name))\n",
    "                os.makedirs(os.path.join(KEYPOINT_PATH, \"V3\", name))\n",
    "            except:\n",
    "                pass\n",
    "            for index, data in df[df[className] == 1].iterrows():\n",
    "                frame = cv2.imread(os.path.join(DATA_PATH, folder, data['filename']))\n",
    "                \n",
    "                image, hand_results, face_results = mediapipe_detection(frame, hands, faces)\n",
    "                \n",
    "                keypoints, use = extract_keypoints_v1(hand_results)\n",
    "                if use:\n",
    "                    npy_path = os.path.join(KEYPOINT_PATH, \"V1\", name, str(len(os.listdir(os.path.join(KEYPOINT_PATH, \"V1\", name)))))\n",
    "                    np.save(npy_path, keypoints)\n",
    "                keypoints, use = extract_keypoints_v2(hand_results)\n",
    "                if use:\n",
    "                    npy_path = os.path.join(KEYPOINT_PATH, \"V2\", name, str(len(os.listdir(os.path.join(KEYPOINT_PATH, \"V2\", name)))))\n",
    "                    np.save(npy_path, keypoints)\n",
    "                keypoints, use = extract_keypoints_v3(hand_results, face_results, image.shape[1], image.shape[0])\n",
    "                if use:\n",
    "                    npy_path = os.path.join(KEYPOINT_PATH, \"V3\", name, str(len(os.listdir(os.path.join(KEYPOINT_PATH, \"V3\", name)))))\n",
    "                    np.save(npy_path, keypoints)\n",
    "\n",
    "                if folder != 'train':\n",
    "                    mirrored_image = cv2.flip(frame, 1)\n",
    "                    image, hand_results, face_results = mediapipe_detection(mirrored_image, hands, faces)\n",
    "                    keypoints, use = extract_keypoints_v1(hand_results)\n",
    "                    if use:\n",
    "                        npy_path = os.path.join(KEYPOINT_PATH, \"V1\", name, str(len(os.listdir(os.path.join(KEYPOINT_PATH, \"V1\", name)))))\n",
    "                        np.save(npy_path, keypoints)\n",
    "                    keypoints, use = extract_keypoints_v2(hand_results)\n",
    "                    if use:\n",
    "                        npy_path = os.path.join(KEYPOINT_PATH, \"V2\", name, str(len(os.listdir(os.path.join(KEYPOINT_PATH, \"V2\", name)))))\n",
    "                        np.save(npy_path, keypoints)\n",
    "                    keypoints, use = extract_keypoints_v3(hand_results, face_results, mirrored_image.shape[1], mirrored_image.shape[0])\n",
    "                    if use:\n",
    "                        npy_path = os.path.join(KEYPOINT_PATH, \"V3\", name, str(len(os.listdir(os.path.join(KEYPOINT_PATH, \"V3\", name)))))\n",
    "                        np.save(npy_path, keypoints)\n",
    "                    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
